{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DSC140A SuperHW"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The problem. Consider the words “meilleur” and “mejor”. In English, both of these words mean “best”\n",
    "– one in French and the other in Spanish. Even if you don’t know how to speak either of these languages,\n",
    "you might be able to guess which word is Spanish and which is French based on the spelling. For example,\n",
    "the word “meilleur” looks more like a French word than a Spanish word due to it containing “ei” and ending\n",
    "in “eur”. On the other hand, the word “mejor” looks more like a Spanish word than a French word due to it\n",
    "containing “j” and ending in “or”. This suggests that there is some statistical structure in the words of these\n",
    "languages that we can use to build a machine learning model capable of distinguishing between French and\n",
    "Spanish without actually understanding the words themselves."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your goal in this problem is to build a machine learning model that can take a word as input and predict\n",
    "whether it is Spanish or French."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "• train_words: a list of n strings, each one of them a word (in either Spanish or French)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "• train_labels: a list of n strings, each one of them either \"spanish\" or \"french\", indicating the\n",
    "language of the corresponding word in train_words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "•  test_words: a list of m strings, each one of them a word (in either Spanish or French)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function should return a list of m strings, each one of them either \"spanish\" or \"french\", indicating\n",
    "your classifier’s prediction for the language of the corresponding word in test_words.\n",
    "Your classify() function is responsible for training your machine learning model on the training data and\n",
    "then using that model to make predictions on the test data.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A good choice of features is important. You might want to consider using the frequency of different\n",
    "letters or pairs of letters in each word as features. For example, one of your features might be whether\n",
    "“el” appears in the word. You do not need to create all of these features by hand – you can use Python\n",
    "to help you generate them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Don’t confuse training accuracy with test accuracy. It is possible to achieve 90%+ training accuracy\n",
    "on this data set, but that doesn’t mean your model will generalize well to the test set.\n",
    "2\n",
    "• Be careful to avoid overfitting! If you use too many features or too complex of a model, you may find\n",
    "that your model performs well on the training data but poorly on the test data.\n",
    "• Start with the simplest models first. We have learned some models in this class that can be implemented\n",
    "using only a couple lines of code (with numpy)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def classify(train_words, train_labels, test_words):\n",
    "    # Extract all unigrams and bigrams from training words\n",
    "    unigrams = set()\n",
    "    bigrams = set()\n",
    "    for word in train_words:\n",
    "        # Convert to lowercase to ensure uniformity\n",
    "        lower_word = word.lower()\n",
    "        # Add unigrams\n",
    "        for c in lower_word:\n",
    "            unigrams.add(c)\n",
    "        # Add bigrams\n",
    "        for i in range(len(lower_word) - 1):\n",
    "            bigram = lower_word[i:i+2]\n",
    "            bigrams.add(bigram)\n",
    "    unigrams = list(unigrams)\n",
    "    bigrams = list(bigrams)\n",
    "    features = unigrams + bigrams\n",
    "    \n",
    "    # Compute prior probabilities\n",
    "    total = len(train_labels)\n",
    "    spanish_count = sum(1 for label in train_labels if label == 'spanish')\n",
    "    french_count = total - spanish_count\n",
    "    prior_spanish = spanish_count / total if total != 0 else 0.5\n",
    "    prior_french = french_count / total if total != 0 else 0.5\n",
    "    \n",
    "    # Initialize counts for features in each class\n",
    "    spanish_feature_counts = {feature: 0 for feature in features}\n",
    "    french_feature_counts = {feature: 0 for feature in features}\n",
    "    \n",
    "    # Populate feature counts for Spanish and French\n",
    "    for word, label in zip(train_words, train_labels):\n",
    "        lower_word = word.lower()\n",
    "        # Extract unigrams and bigrams present in the word\n",
    "        current_unigrams = set(lower_word)\n",
    "        current_bigrams = set()\n",
    "        for i in range(len(lower_word) - 1):\n",
    "            bigram = lower_word[i:i+2]\n",
    "            current_bigrams.add(bigram)\n",
    "        # Update counts\n",
    "        if label == 'spanish':\n",
    "            for u in current_unigrams:\n",
    "                if u in spanish_feature_counts:\n",
    "                    spanish_feature_counts[u] += 1\n",
    "            for b in current_bigrams:\n",
    "                if b in spanish_feature_counts:\n",
    "                    spanish_feature_counts[b] += 1\n",
    "        else:\n",
    "            for u in current_unigrams:\n",
    "                if u in french_feature_counts:\n",
    "                    french_feature_counts[u] += 1\n",
    "            for b in current_bigrams:\n",
    "                if b in french_feature_counts:\n",
    "                    french_feature_counts[b] += 1\n",
    "    \n",
    "    # Calculate probabilities with Laplace smoothing\n",
    "    prob_spanish = {}\n",
    "    prob_french = {}\n",
    "    for feature in features:\n",
    "        prob_spanish[feature] = (spanish_feature_counts[feature] + 1) / (spanish_count + 2)\n",
    "        prob_french[feature] = (french_feature_counts[feature] + 1) / (french_count + 2)\n",
    "    \n",
    "    # Predict for each test word\n",
    "    predictions = []\n",
    "    for word in test_words:\n",
    "        lower_word = word.lower()\n",
    "        test_unigrams = set(lower_word)\n",
    "        test_bigrams = set()\n",
    "        for i in range(len(lower_word) - 1):\n",
    "            bigram = lower_word[i:i+2]\n",
    "            test_bigrams.add(bigram)\n",
    "        \n",
    "        # Compute log probabilities\n",
    "        log_prob_spanish = np.log(prior_spanish) if prior_spanish > 0 else -np.inf\n",
    "        log_prob_french = np.log(prior_french) if prior_french > 0 else -np.inf\n",
    "        \n",
    "        for feature in features:\n",
    "            # Check if the feature is present in the test word\n",
    "            present = False\n",
    "            if feature in unigrams:\n",
    "                present = feature in test_unigrams\n",
    "            else:\n",
    "                present = feature in test_bigrams\n",
    "            \n",
    "            # Update log probabilities\n",
    "            if present:\n",
    "                log_prob_spanish += np.log(prob_spanish[feature])\n",
    "                log_prob_french += np.log(prob_french[feature])\n",
    "            else:\n",
    "                log_prob_spanish += np.log(1 - prob_spanish[feature])\n",
    "                log_prob_french += np.log(1 - prob_french[feature])\n",
    "        \n",
    "        # Determine the predicted label\n",
    "        if log_prob_spanish > log_prob_french:\n",
    "            predictions.append('spanish')\n",
    "        else:\n",
    "            predictions.append('french')\n",
    "    \n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
